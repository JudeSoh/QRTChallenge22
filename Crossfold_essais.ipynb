{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da7ecba-a1f4-4e86-8282-48ef16a58ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.nn.functional import normalize\n",
    "import time\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "np.random.seed(64)\n",
    "\n",
    "#path = '/home/ahardy/ENSchallengeData/' \n",
    "def randomA(D=250, F=10):  \n",
    "    \n",
    "    M = np.random.randn(D,F)\n",
    "    randomStiefel = np.linalg.qr(M)[0] # Apply Gram-Schmidt algorithm to the columns of M\n",
    "    \n",
    "    return randomStiefel\n",
    "\n",
    "\n",
    "\n",
    "def checkOrthonormality(A): \n",
    "    \n",
    "    bool = True\n",
    "    D, F = A.shape   \n",
    "    Error = pd.DataFrame(A.T @ A - np.eye(F)).abs()\n",
    "    \n",
    "    if any(Error.unstack() > 1e-6):\n",
    "        bool = False\n",
    "     \n",
    "    return bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b326ffdc-a26e-453b-a077-611e586d1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./X_train.csv', index_col=0, sep=',')\n",
    "X_train.columns.name = 'date'\n",
    "\n",
    "Y_train = pd.read_csv('./Y_train.csv', index_col=0, sep=',')\n",
    "Y_train.columns.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce4d133d-dbe8-470f-8451-04e79f100b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_Own_CF(n = 10 ):\n",
    "    perm = np.random.permutation(range(50))\n",
    "    valset = perm[:n]\n",
    "    trainset = perm[n:]\n",
    "    X_1 = X_train.iloc[valset,]\n",
    "    X_2 = X_train.iloc[trainset,]\n",
    "    Y_1 = Y_train.iloc[valset,]\n",
    "    Y_2 = Y_train.iloc[trainset,]\n",
    "    return X_2,Y_2,X_1,Y_1\n",
    "\n",
    "X_train,Y_train,X_val,Y_val = My_Own_CF()\n",
    "# On a direct les training sets de la CFvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bf851d-cbaf-4e9b-ad06-5270b94045a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15856\\838770198.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  X_train_reshape = pd.concat([ X_train.T.shift(i+1).stack(dropna=False) for i in range(250) ], 1).dropna()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train_reshape \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([ X_train\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshift(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstack(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m) ], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      2\u001b[0m X_train_reshape\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m251\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeLag\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X_val_reshape \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([ X_val\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshift(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstack(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m) ], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      5\u001b[0m X_val_reshape\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m251\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeLag\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Tout le bazar stdt, pas besoin de se le retaper à chaque fois\u001b[39;00m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train_reshape \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([ X_train\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshift(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstack(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m) ], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      2\u001b[0m X_train_reshape\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m251\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeLag\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X_val_reshape \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([ \u001b[43mX_val\u001b[49m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshift(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstack(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m) ], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      5\u001b[0m X_val_reshape\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m251\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeLag\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Tout le bazar stdt, pas besoin de se le retaper à chaque fois\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_reshape = pd.concat([ X_train.T.shift(i+1).stack(dropna=False) for i in range(250) ], 1).dropna()\n",
    "X_train_reshape.columns = pd.Index(range(1,251), name='timeLag')\n",
    "\n",
    "X_val_reshape = pd.concat([ X_val.T.shift(i+1).stack(dropna=False) for i in range(250) ], 1).dropna()\n",
    "X_val_reshape.columns = pd.Index(range(1,251), name='timeLag')\n",
    "\n",
    "# Tout le bazar stdt, pas besoin de se le retaper à chaque fois\n",
    "targets_t = torch.tensor(Y_train.T.stack().to_numpy().astype(np.float32)) # Le gros vecteur de pred \n",
    "Y_true_t = torch.tensor(Y_train.to_numpy().astype(np.float32)) # La matrice à prédire en torch\n",
    "X_train_reshape_t = torch.tensor(X_train_reshape.to_numpy().astype(np.float32)) # X_train_reshape en torch\n",
    "\n",
    "def randomA(D=250, F=10):  \n",
    "    \n",
    "    M = np.random.randn(D,F)\n",
    "    randomStiefel = np.linalg.qr(M)[0] # Apply Gram-Schmidt algorithm to the columns of M\n",
    "    \n",
    "    return randomStiefel\n",
    "\n",
    "\n",
    "\n",
    "def checkOrthonormality(A): \n",
    "    \n",
    "    bool = True\n",
    "    D, F = A.shape   \n",
    "    Error = pd.DataFrame(A.T @ A - np.eye(F)).abs()\n",
    "    \n",
    "    if any(Error.unstack() > 1e-6):\n",
    "        bool = False\n",
    "     \n",
    "    return bool\n",
    "\n",
    "X = randomA()\n",
    "\n",
    "def fitBeta(A):\n",
    "    \n",
    "    predictors = X_train_reshape @ A # the dataframe of the 10 factors created from A with the (date, stock) in index\n",
    "    targets = Y_train.T.stack()\n",
    "    beta = np.linalg.inv(predictors.T @ predictors) @ predictors.T @ targets\n",
    "    \n",
    "    return beta.to_numpy()\n",
    "\n",
    "checkOrthonormality(X)\n",
    "\n",
    "def metric_train(A, beta): \n",
    "    \n",
    "    if not checkOrthonormality(A):\n",
    "        return -1.0    \n",
    "    \n",
    "    Ypred = (X_train_reshape @ A @ beta).unstack().T    # remet les prédictions sous forme de matrice 50*504. Les vecteurs de Ypred sont les prédictions !!      \n",
    "    Ytrue = Y_train\n",
    "    \n",
    "    Ytrue = Ytrue.div(np.sqrt((Ytrue**2).sum()), 1)    \n",
    "    Ypred = Ypred.div(np.sqrt((Ypred**2).sum()), 1)\n",
    "\n",
    "    meanOverlap = (Ytrue * Ypred).sum().mean()\n",
    "\n",
    "    return  meanOverlap  \n",
    "\n",
    "def metric_val(A, beta): \n",
    "    \n",
    "    if not checkOrthonormality(A):\n",
    "        return -1.0    \n",
    "    \n",
    "    Ypred = (X_val_reshape @ A @ beta).unstack().T    # remet les prédictions sous forme de matrice 50*504. Les vecteurs de Ypred sont les prédictions !!      \n",
    "    Ytrue = Y_val\n",
    "    \n",
    "    Ytrue = Ytrue.div(np.sqrt((Ytrue**2).sum()), 1)    \n",
    "    Ypred = Ypred.div(np.sqrt((Ypred**2).sum()), 1)\n",
    "\n",
    "    meanOverlap = (Ytrue * Ypred).sum().mean()\n",
    "\n",
    "    return  meanOverlap  \n",
    "\n",
    "#On calcule en même temps la fonction à maximiser (sortie 1) et son gradient au point A (sortie 2)\n",
    "def F_et_gradient(A):\n",
    "    \n",
    "    A_t = torch.tensor(A.astype(np.float32),requires_grad = True) # On transforme l'entrée en tensor (on spécifie qu'on va différencier par rapport à A_t !!)\n",
    "    predictors = X_train_reshape_t @ A_t # Les prédicteurs en tensor \n",
    "    beta_t = torch.inverse(predictors.T @ predictors)@predictors.T @targets_t # beta de l'équation normale en tensor\n",
    "    Y_pred_t = (X_train_reshape_t @ A_t @ beta_t).resize(504,40).T #La matrice de prédiction en tensor\n",
    "    f_A = torch.mean(sum(normalize(Y_pred_t,dim=0)*normalize(Y_true_t,dim=0)))\n",
    "    f_A.backward() # On calcule le gradient\n",
    "    A_output = -1*(A_t.grad).numpy() # Et voici le gradient en A !! C'est magique tellement c'est facile... \n",
    "    func_val = -1*f_A.detach().numpy() #la fonction de coût à minimiser évaluée en A \n",
    "    \n",
    "    return func_val, A_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10e7a8e1-c9fc-4c9d-97b2-4ab5ba543f10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = randomA()\n",
    "bX = fitBeta(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e32bed2-758b-43c1-8229-522550971c8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Le grad search sur X_train du CF\n",
    "#with open('Bch4_17_11', 'rb') as f1:\n",
    "  #  XAV = pickle.load(f1)\n",
    "\n",
    "\n",
    "def algo_curv_search(X_start = randomA(),rho1 = 0.000001,rho2 = 0.5,eps = 0.00001,j = 150):\n",
    "    start = time.time()\n",
    "    X = X_start\n",
    "    i,I = 0,np.eye(250)\n",
    "    f,G = F_et_gradient(X) # f is f(X) et G the gradient of f at point X \n",
    "    tau_min = 0.0000001\n",
    "    tau_max = 15\n",
    "    #runn_scores = []\n",
    "    \n",
    "    while  (np.linalg.norm(G) >= eps) and (i <= j):\n",
    "        i += 1\n",
    "        #if i % 5 == 0:\n",
    "            #print(\"Nombre d'itérations:\",i,\"score actuel:\", -f,\"gradient actuel\", np.linalg.norm(G))\n",
    "            #print(time.ctime(time.time() - start)) # to keep track of the evolution of the algorithm\n",
    "        tau_min = 0.000001\n",
    "        tau_max = 15\n",
    "        W = G @ X.T - X @G.T #the skew symmetric matrix of the article _ we try to stick to the notations !  Remember, we need to update these at the end of the Armijo Wolfe conditions.          \n",
    "        DF_0 = np.trace(G.T @ W @ X) #the directional derivative F'(Y(0)). \n",
    "        M_inv_min = np.linalg.inv(I + tau_min/2 * W) # Useful inverse matrices which we do not want to compute twice\n",
    "        M_inv_max = np.linalg.inv(I + tau_max/2 * W)\n",
    "        Y_t_min = M_inv_min @ (I - tau_min/2 * W) @ X\n",
    "        Y_t_max = M_inv_max @ (I - tau_max/2 * W) @ X\n",
    "        f_t_max,G_t_max = F_et_gradient(Y_t_max)\n",
    "        f_t_min,G_t_min = F_et_gradient(Y_t_min)\n",
    "        cond_min = (f_t_min <= f + rho1 * tau_min * DF_0) # AW cond at tau_min\n",
    "        cond_max = (.5 * np.trace(G_t_max.T @ M_inv_max @ W @ (X + Y_t_max)) >= rho2* DF_0) #AW cond at tau_max\n",
    "        while (not cond_min) or (not cond_max) :\n",
    "            if not cond_min:\n",
    "                #print(\"Boucle d'itération:\",i,\"là c'est cond_min:\", tau_min,tau_max) #pour check\n",
    "                if tau_min < 0.01:\n",
    "                    tau_min = min(10*tau_min,tau_max - 0.0000000001)\n",
    "                else :\n",
    "                    tau_min = min(1.05 * tau_min,tau_max - 0.000000001) \n",
    "                #tau_min = .5*(tau_min + tau_max) # dichotomy is way too violent in this case... \n",
    "                M_inv_min = np.linalg.inv(I + tau_min/2 * W)\n",
    "                Y_t_min = M_inv_min @ (I - tau_min/2 * W) @ X\n",
    "                f_t_min,G_t_min = F_et_gradient(Y_t_min)\n",
    "                cond_min = (f_t_min <= f + rho1 * tau_min * DF_0) # AW cond at tau_min\n",
    "            elif not cond_max:\n",
    "                #print(\"Boucle d'itération:\",i,\"là c'est cond_max:\", tau_min,tau_max) #pour check\n",
    "                tau_max = max(tau_min+ 0.000000001,min(.95*tau_max,.5*(tau_max+tau_min))) # just to ensure that we always have tau_max > tau_min\n",
    "                # tau_max = .5*(tau_min + tau_max) same comment\n",
    "                M_inv_max = np.linalg.inv(I + tau_max/2 * W)\n",
    "                Y_t_max = M_inv_max @ (I - tau_max/2 * W) @ X\n",
    "                f_t_max,G_t_max = F_et_gradient(Y_t_max)\n",
    "                cond_max = (.5 * np.trace(G_t_max.T @ M_inv_max @ W @ (X + Y_t_max)) >= rho2* DF_0) #AW cond at tau_max\n",
    "                \n",
    "        tau_f = .5*(tau_min + tau_max) # t_k satisfying both AW conditions\n",
    "        Y_t_f = np.linalg.inv(I + tau_f/2 * W) @ (I - tau_f/2 * W) @ X\n",
    "        f_t_f,G_t_f = F_et_gradient(Y_t_f)\n",
    "        #cond_f_1 = (f_t_f <= f + rho1 * tau_f * DF_0) #for control\n",
    "        #cond_f_2 = (.5 * np.trace(G_t_f.T @ np.linalg.inv(I + tau_f/2 * W) @ W @ (X + Y_t_f)) >= rho2* DF_0) #for control\n",
    "        #print(\"Boucle d'itération:\",i,\"un tau qui va\", tau_f, cond_f_1, cond_f_2 ) #for control \n",
    "        X = np.linalg.inv(I + tau_f/2 * W) @ (I - tau_f/2 * W) @ X\n",
    "        f,G = F_et_gradient(X)\n",
    "        #runn_scores.append(f)\n",
    "        #if npmean(runn_scores[::-20])\n",
    "        \n",
    "    print(\"Le score final est:\",-f)\n",
    "    return X,-f\n",
    "        \n",
    "    \n",
    "# renvoie n top scorers pour Xtrain\n",
    "def resultatsgrad(n = 5): \n",
    "    mat=[]\n",
    "    for i in range(n):\n",
    "        X = randomA()\n",
    "        E,sc = algo_curv_search(X_start=X)\n",
    "        mat.append(E)\n",
    "    return mat    \n",
    "\n",
    "\n",
    "# On teste les n sur Xval; on renvoie la liste des scores sur X_val\n",
    "def top_scorer(E):\n",
    "    res = []\n",
    "    i=1\n",
    "    for mat in E:\n",
    "        beta = fitBeta(mat)\n",
    "        score = metric_val(mat,beta)\n",
    "        print(\"Le score pour la matrice\",i,\"est\",score)\n",
    "        res.append(score)\n",
    "        i+=1\n",
    "    k = np.argmax(res)\n",
    "    print(\"Le top scorer est le no\",k)\n",
    "    return E[k]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67bcfc75-9258-488e-9299-ee8ec8a57566",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:760: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score final est: 0.1550392508506775\n",
      "Le score final est: 0.15503928065299988\n",
      "Le score final est: 0.15503928065299988\n",
      "Le score final est: 0.15503928065299988\n",
      "Le score final est: 0.15503928065299988\n",
      "Le score pour la matrice 1 est 0.07336106643352831\n",
      "Le score pour la matrice 2 est 0.07336514250306797\n",
      "Le score pour la matrice 3 est 0.07336575636435579\n",
      "Le score pour la matrice 4 est 0.07336742060891391\n",
      "Le score pour la matrice 5 est 0.07336366699792572\n",
      "Le top scorer est le no 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.04319745, -0.09150063,  0.01749819, ...,  0.02478551,\n",
       "        -0.05702485,  0.05886815],\n",
       "       [ 0.00387718, -0.023314  , -0.16405323, ...,  0.03729388,\n",
       "        -0.14377759, -0.14592098],\n",
       "       [-0.06404435,  0.08790449, -0.01489486, ...,  0.03066821,\n",
       "         0.04115303,  0.01135247],\n",
       "       ...,\n",
       "       [ 0.05625663, -0.03724243,  0.05794762, ..., -0.0407986 ,\n",
       "         0.12884013, -0.00611646],\n",
       "       [-0.11360385, -0.00861126, -0.01370783, ...,  0.01199482,\n",
       "         0.16568935, -0.10506742],\n",
       "       [ 0.00898153,  0.03345294,  0.04480027, ...,  0.06473483,\n",
       "         0.0258555 , -0.04375351]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = resultatsgrad()\n",
    "top_scorer(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcd387e2-8837-4a0b-ab90-229168cf8db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ac70ac4-045e-4b96-8198-831769c8bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:760: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score final est: 0.16034188866615295\n",
      "Le score final est: 0.16034188866615295\n",
      "Le score final est: 0.16034188866615295\n",
      "Le score final est: 0.16034188866615295\n",
      "Le score final est: 0.16034188866615295\n"
     ]
    }
   ],
   "source": [
    "M = resultatsgrad(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576a1819-1b10-4ea7-8964-3dfec7f9609a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkOrthonormality(XAV)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42cb5b84-e0b1-40e0-b9d2-7d2a0748a87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02976787,  0.05537492, -0.07782243, ..., -0.05068061,\n",
       "        -0.09802267,  0.0639761 ],\n",
       "       [-0.06782048, -0.07839067,  0.00068759, ..., -0.04494692,\n",
       "         0.05838768, -0.0069381 ],\n",
       "       [-0.03383288, -0.14343419, -0.05779111, ..., -0.05000139,\n",
       "        -0.0081585 ,  0.00710922],\n",
       "       ...,\n",
       "       [-0.01180972, -0.01559474, -0.01554548, ..., -0.15532192,\n",
       "        -0.01110967,  0.02181123],\n",
       "       [-0.02048849,  0.02301782,  0.10225766, ..., -0.11324442,\n",
       "         0.00672905,  0.15530524],\n",
       "       [-0.12801446,  0.05585329,  0.0011197 , ..., -0.05215066,\n",
       "        -0.00377846, -0.06848738]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dfa60ef-bbcd-421d-82b5-d99250e4c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_last_res = [31, 33, 18, 10, 23, 12, 43,  0,  6,  5]\n",
    "locations = [i for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "082866a6-1a5e-4cc7-b15b-3954c03ce365",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in locations_last_res:\n",
    "    locations.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2d09fe-8c2a-4dc7-8760-e30ffbe2a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('Bch_22_11', 'rb') as f1:\n",
    "    XAV = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8414d27c-b7ed-4aa8-ba0c-b1c48ea74b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X_train.iloc[locations,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f39343c2-352d-42cb-a1ca-388aa5704dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = Y_train.iloc[locations,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0d7158-871d-4d77-952e-e0843ac742fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15856\\4063455792.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  X_1_reshape = pd.concat([ X_train.T.shift(i+1).stack(dropna=False) for i in range(250) ], 1).dropna()\n"
     ]
    }
   ],
   "source": [
    "X_1_reshape = pd.concat([ X_train.T.shift(i+1).stack(dropna=False) for i in range(250) ], 1).dropna()\n",
    "X_1_reshape.columns = pd.Index(range(1,251), name='timeLag')\n",
    "\n",
    "#X_val_reshape = pd.concat([ X_val.T.shift(i+1).stack(dropna=False) for i in range(250) ], 1).dropna()\n",
    "#X_val_reshape.columns = pd.Index(range(1,251), name='timeLag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35fe0a-31f4-4582-b044-7efbee601476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ff72bf3-17e0-4325-ba61-0f452e8130c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25200, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = X_1_reshape @ XAV # the dataframe of the 10 factors created from A with the (date, stock) in index\n",
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b57fd046-ef2c-48be-8fd3-71082eb8baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = Y_1.T.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "834169ff-f937-4a49-9318-49a2bf9b1d0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matrices are not aligned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m predictors \u001b[38;5;241m=\u001b[39m X_1_reshape \u001b[38;5;241m@\u001b[39m XAV \u001b[38;5;66;03m# the dataframe of the 10 factors created from A with the (date, stock) in index\u001b[39;00m\n\u001b[0;32m      2\u001b[0m targets \u001b[38;5;241m=\u001b[39m Y_1\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mstack()\n\u001b[1;32m----> 3\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__matmul__\u001b[39m(\n\u001b[0;32m   1549\u001b[0m     \u001b[38;5;28mself\u001b[39m, other: AnyArrayLike \u001b[38;5;241m|\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series\n\u001b[0;32m   1550\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;124;03m    Matrix multiplication using binary `@` operator in Python>=3.5.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:1508\u001b[0m, in \u001b[0;36mDataFrame.dot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1506\u001b[0m common \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39munion(other\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(common) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(common) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(other\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m-> 1508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrices are not aligned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1510\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39mcommon, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1511\u001b[0m right \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mreindex(index\u001b[38;5;241m=\u001b[39mcommon, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: matrices are not aligned"
     ]
    }
   ],
   "source": [
    "beta = np.linalg.inv(predictors.T @ predictors) @ predictors.T @ targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3daafd8-aa98-4db8-a70a-bd9a580b2b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
